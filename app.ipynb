{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYZE, VISUALIZE AND PREPARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessarry libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "df = pd.read_csv(\"customer.csv\", encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick look dataset\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing its shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting its basic information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename wrong column name\n",
    "df.rename(columns ={'Country;;;;;;':'Country'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix wrong values\n",
    "df['Country'] = df['Country'].str.replace(';', '')\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix wrong values\n",
    "df['Description'] = df['Description'].str.replace('.', '')\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look top 10 products that sold\n",
    "df[\"StockCode\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing top 10 products that sold using countplot\n",
    "top10_product = df['StockCode'].value_counts().head(10).index.tolist()\n",
    "\n",
    "plt.figure(figsize= (15, 8))\n",
    "sns.countplot(x= 'StockCode', data= df, order= top10_product,  palette= \"Set2\")\n",
    "plt.title('Top 10 Products')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chceking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete empties\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chceking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for redundancy\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping redundancy\n",
    "df.drop_duplicates(keep= 'first', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for redundancy\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting its basic information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n",
    "\n",
    "df = df[~df[\"InvoiceNo\"].str.contains(\"C\", na=False)]\n",
    "\n",
    "# Quantity is very low of number due to cancellation of invoice that includes letter of \"C\"\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type\n",
    "#Categorical value\n",
    "df['InvoiceNo'] = df['InvoiceNo'].astype(object)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type\n",
    "df['Quantity'] = df['Quantity'].astype(int)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type\n",
    "#categorical value\n",
    "df['CustomerID'] = df['CustomerID'].astype(object)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing top 10 frequent customer using countplot\n",
    "top10_customer = df['CustomerID'].value_counts().head(10).index\n",
    "\n",
    "plt.figure(figsize= (8,5))\n",
    "sns.countplot(x= 'CustomerID', data= df, order= top10_customer,  palette= 'crest')\n",
    "plt.title('Top 10 Customer')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check value counts\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check mathematical data\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new colunm for costumer analysis\n",
    "df[\"TotalPrice\"]=df[\"Quantity\"]*df[\"UnitPrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total price by country\n",
    "df.groupby(\"Country\").agg({\"TotalPrice\":\"sum\"}).sort_values(\"TotalPrice\", ascending=False ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing total sales perday using lineplot\n",
    "sales_perday = df.groupby('InvoiceDate')['TotalPrice'].sum().sort_values(ascending= False).to_frame().reset_index()\n",
    "\n",
    "plt.figure(figsize= (15,5))\n",
    "sns.lineplot(x= 'InvoiceDate', y= 'TotalPrice', data= sales_perday, color= '#0a437a')\n",
    "plt.title('Total Sales per day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top ten country's customer\n",
    "df.Country.value_counts()[:10].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top ten country by total price\n",
    "df.groupby(\"Country\").agg({\"TotalPrice\":\"sum\"}).sort_values(\"TotalPrice\", ascending=False )[:10].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check mathematical data\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer purchased products at last time\n",
    "\n",
    "df[\"InvoiceDate\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the latest invoice date in the dataset\n",
    "latest_invoice_date = df['InvoiceDate'].max()\n",
    "latest_invoice_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoice date before three months of latest date\n",
    "mon3_ret_date = pd.Timestamp('2011-09-01 12:50:00')\n",
    "mon3_ret_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the first part of data that doesn't have last 3 months of transaction\n",
    "\n",
    "df_part1 = df.copy() # creating copy\n",
    "df_part1.set_index('InvoiceDate', inplace= True) # setting Date as index\n",
    "df_part1 = df_part1.loc[:'2011-09-09 12:50:00'] # slicing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reseting the index\n",
    "df_part1.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFM ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the recency of each customer\n",
    "\n",
    "recency = df_part1.groupby('CustomerID').agg({'InvoiceDate': lambda x : \n",
    "                                              (latest_invoice_date - x.max()).days}).reset_index() # calculating recency\n",
    "\n",
    "recency.rename(columns= {'InvoiceDate':'Recency'}, inplace= True) # renaming columns\n",
    "recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the frequency of each customer\n",
    "\n",
    "frequency = df_part1.groupby('CustomerID').agg({'CustomerID':'count'}) # calculating frequency\n",
    "\n",
    "frequency.rename(columns= {'CustomerID':'Frequency'}, inplace= True) # renaming columns\n",
    "frequency.reset_index(inplace= True) # resetting index\n",
    "\n",
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the monetary of each customer\n",
    "\n",
    "monetary = df_part1.groupby('CustomerID').agg({'TotalPrice':'sum'}).reset_index() # calculting monetary\n",
    "\n",
    "monetary.rename(columns= {'TotalPrice':'Monetary'}, inplace= True) # renaming columns\n",
    "monetary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new dataframe RFM with recency, frequency and monetary of each customer\n",
    "rfm = pd.concat([recency.iloc[:,:], frequency.iloc[:,-1], monetary.iloc[:,-1]], axis= 1)\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describing feature variables of RFM dataframe\n",
    "rfm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the distribution of feature variables in RFM dataframe using distplot\n",
    "fig, axis = plt.subplots(3,1, figsize= (6,8))\n",
    "\n",
    "for i,feature in enumerate(['Recency', 'Frequency', 'Monetary']):\n",
    "    sns.distplot(x= rfm[feature], kde= True, ax= axis[i], color= '#7e4071', axlabel= feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Recency values should be higher than 1, so today_date can be choosen maximum value +2\n",
    "\n",
    "today_date = pd.datetime(2011, 12, 11)\n",
    "\n",
    "rfm = df.groupby(\"CustomerID\").agg({\"InvoiceDate\": lambda date: (today_date - date.max()).days,\n",
    "                                     \"InvoiceNo\": lambda InvoiceNo: InvoiceNo.nunique(),\n",
    "                                     \"TotalPrice\":lambda TotalPrice: TotalPrice.sum()})\n",
    "\n",
    "rfm.columns = [\"Recency\", \"Frequency\", \"Monetary\"]\n",
    "\n",
    "rfm = rfm[rfm[\"Monetary\"] > 0]\n",
    "\n",
    "rfm.describe().T\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc = {\"figure.figsize\" : (18,5)})\n",
    "\n",
    "sns.boxplot(rfm[\"Monetary\"], palette=\"summer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {\"figure.figsize\" : (18,5)})\n",
    "\n",
    "sns.boxplot(rfm[\"Frequency\"], palette=\"summer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {\"figure.figsize\" : (18,5)})\n",
    "\n",
    "sns.boxplot(rfm[\"Recency\"], palette=\"summer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency, recency, monetary are scaled to with 'qcut' function for assesting to these values.\n",
    "rfm[\"Recency_score\"] = pd.cut(rfm[\"Recency\"], 5, labels=[5,4,3,2,1])\n",
    "\n",
    "rfm[\"Monetary_score\"] = pd.cut(rfm[\"Monetary\"], 5, labels=[1,2,3,4,5])\n",
    "\n",
    "rfm[\"Frequency_score\"] = pd.cut(rfm[\"Frequency\"].rank(method=\"first\"), 5, labels=[1,2,3,4,5])\n",
    "\n",
    "rfm[\"RFM_SCORE\"] = (rfm[\"Recency_score\"].astype(int) + rfm[\"Frequency_score\"].astype(int) + rfm[\"Monetary_score\"].astype(int))\n",
    "\n",
    "rfm.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(rfm,hue=\"Frequency_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(rfm,hue=\"Recency_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the required independent feature variables of RFM dataframe to X_rfm variable\n",
    "X_rfm = rfm[['Recency_score', 'Frequency_score', 'Monetary_score', 'RFM_SCORE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing the data with StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "X_rfm = std_scaler.fit_transform(X_rfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building k-means clustering model and by elbow curve method finding the optimal cluster value\n",
    "\n",
    "list_wcss = [] # empty list to store Within Cluster Sum of Square values\n",
    "\n",
    "k = range(1,11)\n",
    "\n",
    "for i in k:\n",
    "    \n",
    "    kmeans = KMeans(n_clusters= i, random_state= 42) # building k-means clustering model \n",
    "    kmeans.fit(X_rfm) # fitting data into model\n",
    "    \n",
    "    list_wcss.append(kmeans.inertia_) # appending WCSS value to list_wcss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting wcss against k to find optimal k value\n",
    "plt.plot(k, list_wcss, 'rD--')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmenting each customer into different segments based on their RFM scores\n",
    "\n",
    "rfm['Seg_Num'] = pd.cut(rfm['RFM_SCORE'], bins= [0, 6, 10, 18], \n",
    "                               labels= [3,2,1]) # getting Segment_Number for each customer\n",
    "\n",
    "rfm['Segment_Label'] = pd.cut(rfm['RFM_SCORE'], bins= [0, 6, 10, 18], \n",
    "                              labels= ['Basic Customer', 'Standard Customer',\n",
    "                                       'Prime Customer']) # getting Segment_Label for each customer\n",
    "\n",
    "rfm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the different segment of customers with median value\n",
    "rfm.groupby('Segment_Label')[['Recency', 'Frequency', 'Monetary']].median().round().reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the RFM Scores of different segment of customers using strip plot\n",
    "sns.stripplot(x= 'Seg_Num', y= 'RFM_SCORE', data= rfm, hue= 'Segment_Label', palette= 'mako', jitter=False)\n",
    "plt.title('RFM Scores of each Segment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the distribution of different segment of customers with their RFM score using violin plot\n",
    "sns.violinplot(x= 'Seg_Num', y= 'RFM_SCORE', data= rfm, hue= 'Segment_Label', palette= 'mako')\n",
    "plt.title('Distribution of RFM Scores of each Segment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the different segment of customers and thier recency, frequency and monetary values using strip plot\n",
    "fig, axis = plt.subplots(3,1, figsize= (5,10))\n",
    "\n",
    "for i,feature in enumerate(['Recency', 'Frequency', 'Monetary']):\n",
    "    sns.stripplot(x= 'Seg_Num', y= feature, data= rfm, hue= 'Segment_Label', palette= 'mako', ax= axis[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing the percentage of each segment of customers using pie chart\n",
    "segment_count = rfm['Segment_Label'].value_counts()\n",
    "\n",
    "plt.pie(segment_count.values, labels= segment_count.index, autopct='%1.1f%%')\n",
    "plt.title('Percentage of Customer in each Segment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHURN ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the second part of data that have only last 3 months of transaction\n",
    "\n",
    "df_part2 = df.copy() # creating copy\n",
    "df_part2.set_index('InvoiceDate', inplace= True) # setting Date as index\n",
    "\n",
    "df_part2 = df_part2.loc['2011-09-01 12:50:00':] # slicing the data\n",
    "df_part2.reset_index(inplace= True) # resetting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing the data of df_part2\n",
    "df_part2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing the number of customers in df_part2\n",
    "df_part2['CustomerID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing the number of customers in df_part2\n",
    "df_part1['CustomerID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the number of customers in part1 and part2\n",
    "part1_customer = df_part1['CustomerID'].sort_values().unique()\n",
    "part2_customer = df_part2['CustomerID'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding how many new customers in part2\n",
    "\n",
    "New_customers = [] # empty list to store new customers ID\n",
    "\n",
    "for i in part2_customer:\n",
    "    if i in part1_customer: # checking customer of part2 data in part1 data\n",
    "        pass\n",
    "    else:\n",
    "        New_customers.append(i) # else appending customer ID to New_customers\n",
    "        \n",
    "print(f'Total Number of New Customers: {len(New_customers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding how many old customers made transaction in last three months\n",
    "\n",
    "R_next_3months = [] # empty list to store customer ID\n",
    "\n",
    "for i in part1_customer:\n",
    "    if i in part2_customer: # checking customer of part1 data in part2 data \n",
    "        R_next_3months.append('Yes') # if true append Yes\n",
    "\n",
    "    else:\n",
    "        R_next_3months.append('No') # else append No\n",
    "\n",
    "\n",
    "# R_next_3months listesi oluşturuluyor\n",
    "#R_next_3months = ['Yes' if customer_id in part2_customer else 'No' for customer_id in rfm.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(R_next_3months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm['R_Next_3Months'] =  R_next_3months # adding the new feature variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing RFM dataframe\n",
    "rfm.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm['R_Next_3Months'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm['R_Next_3Months'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding whether the customer is churned or not based on conditions\n",
    "\n",
    "Churn = [] # empty list to store the status of churn of customer\n",
    "\n",
    "for i,j in enumerate(rfm['CustomerID']):\n",
    "    \n",
    "    if rfm['Recency'][i] <= 90 and rfm['R_Next_3Months'][i] == 'Yes': \n",
    "        Churn.append('No')\n",
    "        \n",
    "    elif rfm['Recency'][i] <= 90 and rfm['R_Next_3Months'][i] == 'No':\n",
    "        \n",
    "        if rfm['Frequency'][i] <= 15:\n",
    "            Churn.append('High Risk')\n",
    "            \n",
    "        else:\n",
    "            Churn.append('Low Risk')\n",
    "            \n",
    "    elif rfm['Recency'][i] > 90 and rfm['R_Next_3Months'][i] == 'Yes':\n",
    "        \n",
    "        if rfm['Frequency'][i] > 15:\n",
    "            Churn.append('No')\n",
    "            \n",
    "        else:\n",
    "            Churn.append('Low Risk')\n",
    "            \n",
    "    elif rfm['Recency'][i] > 90 and rfm['R_Next_3Months'][i] == 'No':\n",
    "        Churn.append('Yes')\n",
    "        \n",
    "rfm['Churn'] = Churn # adding the new feature variable churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing the percentage of each class in churn using pie chart\n",
    "churn_count = rfm['Churn'].value_counts()\n",
    "\n",
    "plt.pie(churn_count.values, labels= churn_count.index, autopct='%1.1f%%')\n",
    "plt.title('Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing different segment of customers and thier churn class\n",
    "sns.countplot(x= 'Churn', data= rfm, hue= 'Segment_Label', palette= 'rocket')\n",
    "plt.title('Count of Customers in each Segment with Churn Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing and knowing the percentage of churn class for different segment of customers \n",
    "segment_list = rfm['Segment_Label'].unique().sort_values(ascending= False)\n",
    "\n",
    "for i in segment_list:\n",
    "    segment = rfm[['Segment_Label','Churn']][rfm.Segment_Label == i]\n",
    "    segment_churn = segment.value_counts().to_frame().reset_index().rename(columns= {0:'count'})\n",
    "    \n",
    "    plt.pie(x= segment_churn['count'], labels= segment_churn['Churn'], autopct= '%.1f%%')\n",
    "    plt.title(i)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the datatype of categorical feature from int to object\n",
    "rfm[['CustomerID', 'Seg_Num', 'Segment_Label']] = rfm[['CustomerID', 'Seg_Num', 'Segment_Label']].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the datatype of categorical feature from int to object\n",
    "rfm[['Recency_score', 'Monetary_score', 'Frequency_score']] = rfm[['Recency_score', 'Monetary_score', 'Frequency_score']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating correlation matrix for the numeric feature variables\n",
    "corr = rfm[['Recency', 'Frequency', 'Monetary', 'Recency_score', 'Monetary_score', 'Frequency_score', 'RFM_SCORE']].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the correlation between numeric feature variables using heat map\n",
    "plt.figure(figsize= (8,6))\n",
    "sns.heatmap(data= corr, fmt= '.2f', linewidths= 0.2, linecolor= 'white', cmap= 'Blues', annot= True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the variance in each features\n",
    "#rfm.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unwanted and multicollinearity feature variables\n",
    "df_segment = rfm.copy() # copy of RFM dataframe\n",
    "df_segment.drop(['CustomerID', 'Recency_score', 'Frequency_score', 'Monetary_score', 'Seg_Num'], axis= 1, inplace= True) # dropping\n",
    "df_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing and getting know whether independent feature variables having outlier using box plot\n",
    "num_features = df_segment.select_dtypes(exclude= 'object').columns\n",
    "\n",
    "fig, axis = plt.subplots(1,4,figsize=(10,3))\n",
    "axis = axis.flatten()\n",
    "\n",
    "for i,feature in enumerate(num_features):\n",
    "    sns.boxplot(y= feature, data= df_segment, ax= axis[i], color= '#4c9085')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the feature variables having outliers\n",
    "outliers_features = ['Frequency', 'Monetary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing outliers using zscore \n",
    "from scipy import stats\n",
    "zscore_frequency = np.abs(stats.zscore(df_segment['Frequency'])) # calculating Z-score for frequency\n",
    "zscore_monetary = np.abs(stats.zscore(df_segment['Monetary'])) # calculating Z-score for monetary\n",
    "\n",
    "threshold = 3 # setting threshold value\n",
    "\n",
    "outliers_frequency = list(np.where(zscore_frequency>threshold)[0]) # getting outliers index in frequency\n",
    "outliers_monetary = list(np.where(zscore_monetary>threshold)[0]) # getting outliers index in monetary\n",
    "\n",
    "outliers_indices = list(set(outliers_frequency + outliers_monetary)) # creating a set for getting unique index of outliers\n",
    "outliers_indices.sort() # sorting the list\n",
    "\n",
    "df_segment = df_segment.drop(df_segment.index[outliers_indices]) # dropping outlier records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical variable using Label Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df_segment['R_Next_3Months'] = labelencoder.fit_transform(df_segment['R_Next_3Months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_segment['Segment_Label'] = labelencoder.fit_transform(df_segment['Segment_Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_segment['Churn'] = labelencoder.fit_transform(df_segment['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning variables for independent and dependent feature variables\n",
    "\n",
    "X = df_segment.drop(['Churn'], axis= 1) # independent feature variables\n",
    "y = df_segment[['Churn']] # dependent feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization of independent variables\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "X = std.fit_transform(X)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the 0 values with mean\n",
    "'''\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values = 0, strategy='mean')\n",
    "\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.fit_transform(X_test)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see the shape of our train and test datasets\n",
    "\n",
    "print('Shape training set: X:{}, y:{}'.format(X_train.shape, y_train.shape))\n",
    "print('Shape test set: X:{}, y:{}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling Libraries\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(models):\n",
    "    \"\"\"\n",
    "    Takes a list of models and returns chart of cross validation scores using mean accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cross validate model with Kfold stratified cross val\n",
    "    kfold = StratifiedKFold(n_splits = 10)\n",
    "    \n",
    "    result = []\n",
    "    for model in models:\n",
    "        result.append(cross_val_score(estimator=model, X=X_train, y=y_train, scoring=\"accuracy\", cv=kfold, n_jobs=1))  # n_jobs=1\n",
    "\n",
    "    cv_means = []\n",
    "    cv_std = []\n",
    "    for cv_result in result:\n",
    "        cv_means.append(cv_result.mean())\n",
    "        cv_std.append(cv_result.std())\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"CrossValMeans\": cv_means,\n",
    "        \"CrossValerrors\": cv_std,\n",
    "        \"Models\": [\n",
    "            \"LogisticRegression\",\n",
    "            \"DecisionTreeClassifier\",\n",
    "            \"AdaBoostClassifier\",\n",
    "            \"SVC\",\n",
    "            \"RandomForestClassifier\",\n",
    "            \"GradientBoostingClassifier\",\n",
    "            \"KNeighborsClassifier\"\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Generate chart\n",
    "    bar = sns.barplot(x=\"CrossValMeans\", y=\"Models\", data=result_df, orient=\"h\")\n",
    "    bar.set_xlabel(\"Mean Accuracy\")\n",
    "    bar.set_title(\"Cross validation scores\")\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling step Test differents algorithms \n",
    "random_state = 42\n",
    "models = [\n",
    "    LogisticRegression(random_state = random_state, solver='liblinear'),\n",
    "    DecisionTreeClassifier(random_state = random_state),\n",
    "    AdaBoostClassifier(DecisionTreeClassifier(random_state = random_state), random_state = random_state, learning_rate = 0.2),\n",
    "    SVC(random_state = random_state),\n",
    "    RandomForestClassifier(random_state = random_state),\n",
    "    GradientBoostingClassifier(random_state = random_state),\n",
    "    KNeighborsClassifier(),\n",
    "]\n",
    "evaluate_model(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "def analyze_grid_result(grid_result):\n",
    "\n",
    "    # Best parameters and accuracy\n",
    "    print(\"Tuned hyperparameters: (best parameters) \", grid_result.best_params_)\n",
    "    print(\"Accuracy :\", grid_result.best_score_)\n",
    "    \n",
    "    means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "    stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "    for mean, std, params in zip(means, stds, grid_result.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "    print(\"Detailed classification report:\")\n",
    "    y_true, y_pred = y_test, grid_result.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and parameters for LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "solvers = ['newton-cg', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# Define grid search\n",
    "grid = dict(solver = solvers, penalty = penalty, C = c_values)\n",
    "cv = StratifiedKFold(n_splits = 50, random_state = 1, shuffle = True)\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid, cv = cv, scoring = 'accuracy', error_score = 0)\n",
    "logi_result = grid_search.fit(X_train, y_train)\n",
    "# Logistic Regression Hyperparameter Result\n",
    "analyze_grid_result(logi_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model with the best parameters\n",
    "\n",
    "model = LogisticRegression(C=0.1, penalty='l2', solver='liblinear')\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Prediction and Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
